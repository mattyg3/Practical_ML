---
title: "Final Project"
author: "Matt Goldsmith"
date: "November 25, 2018"
output: html_document
---


#Load & Process Data for Modeling
```{r}
#load data
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")



#Remove columns with NA (Test set)
test2 <- test[,colSums(is.na(test)) == 0]

set.seed(888)
x <- sample(1:nrow(train), 0.7*nrow(train))
sub_train <- train[x,]
sub_test <- train[-x,]


```


#Random Forest

###Initial Random Forest (all variables)
```{r}
library(randomForest)
t_names <- names(test2)
f <- paste(t_names[5:59],collapse = "+")
ff <- as.formula(paste("classe", f, sep = "~"))
rf1 <- randomForest(ff, data=sub_train)
yhat1 <- predict(rf1, newdata = sub_test)
table(yhat1,sub_test$classe)
correct1 <- ifelse(yhat1 == sub_test$classe,1,0)
acc <- sum(correct1)/length(correct1)
acc
```
In the table above and with the calculated accuracy of 99.7%, we can see that our initial model did very well at predicting "classe" using all variables available in Test set.

###Subset training data to most significant variables from initial random forest

In Figure 1 in Appendix, we can see that the most significant variable is cvtd_timestamp, followed by num_window and roll_belt. Now we will select only the most important variables and re-run a random forest. 
```{r}
z <- importance(rf1)
z_names <- row.names(z)
#take variables with importance >= 250
z1 <- ifelse(z>=250,1,0)
z2 <- as.data.frame(cbind(z_names, z1,z))
z3 <- z2[z2$MeanDecreaseGini == 1, ]
```



###Second Random Forest (importance >= 250)
```{r}
t_names <- as.vector(z3$z_names)
f <- paste(t_names,collapse = "+")
ff <- as.formula(paste("classe", f, sep = "~"))
rf2 <- randomForest(ff, data=sub_train)
yhat2 <- predict(rf2, newdata = sub_test)
table(yhat2,sub_test$classe)
correct2 <- ifelse(yhat2 == sub_test$classe,1,0)
acc2 <- sum(correct2)/length(correct2)
acc
```
As seen above, even when reducing the model to only the most important variables, we saw no improvement in our model's accuracy.

#Appendix

####Figure 1
```{r}
varImpPlot(rf1)
```

